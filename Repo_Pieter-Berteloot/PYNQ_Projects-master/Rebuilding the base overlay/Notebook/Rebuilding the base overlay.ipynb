{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebuilding the base overlay\n",
    "The full vivado project can be found in https://github.com/Pieter-Berteloot/PYNQ_Video_overlay.\n",
    "Once we succesfully rebuild the base over to our video_stream overlay, we can now test out if everything still works.\n",
    "\n",
    "**Place the .bit and .tcl file in the following directory:**\n",
    "\n",
    "\\\\192.168.2.99\\xilinx\\pynq\\overlays\\base\n",
    "\n",
    "\n",
    "- The **bit file** can be found after generating the bitstream in:\n",
    "    \n",
    "   \\boards\\Pynq-Z1\\base\\base\\base.runs\\impl_1\n",
    "    \n",
    "    \n",
    "- The **TCL file** after running the write_bd_tcl top.tcl command\n",
    "    \n",
    "    c:/Users/[user]/AppData/Roaming/Xilinx/Vivado/top.tcl\n",
    "\n",
    "\n",
    "All the code here can be found in the **hdmi_introduction example notebook**:\n",
    "\n",
    "# New Style HDMI input and Pixel Formatting\n",
    "\n",
    "This notebook introduces the new features of PYNQ 2.0 for interacting the video pipeline. The API has been completely\n",
    "redesigned with high performance image processing applications in mind.\n",
    "\n",
    "To start with download the base overlay and instantate the HDMI input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import Overlay\n",
    "from pynq import MMIO\n",
    "from pynq.lib.video import *\n",
    "\n",
    "base = Overlay(\"/home/xilinx/pynq/overlays/base/top.bit\")\n",
    "base.download()\n",
    "\n",
    "hdmi_in = base.video.hdmi_in\n",
    "hdmi_out = base.video.hdmi_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "First we'll use the default pixel format which is 24 bit-per-pixel BGR formatted data for ease of use with OpenCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_in.configure()\n",
    "hdmi_out.configure(hdmi_in.mode)\n",
    "\n",
    "hdmi_in.start()\n",
    "hdmi_out.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The monitor should turn on and show a blank screen. To pass the image data through we can tie the output to the input. The tie will last until we send something else to be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_in.tie(hdmi_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this provides for a fast way of passing video data through the pipeline there is no way to access or modify the frames. For that we a loop calling `readframe` and `writeframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "numframes = 600\n",
    "start = time.time()\n",
    "\n",
    "for _ in range(numframes):\n",
    "    f = hdmi_in.readframe()\n",
    "    hdmi_out.writeframe(f)\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Frames per second:  \" + str(numframes / (end - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can start adding some OpenCV processing into the mix. For all of these examples we are going to use a lapcian gradient filter. The first loop is going to perform the grayscale conversion in software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "numframes = 10\n",
    "grayscale = np.ndarray(shape=(hdmi_in.mode.height, hdmi_in.mode.width),\n",
    "                       dtype=np.uint8)\n",
    "result = np.ndarray(shape=(hdmi_in.mode.height, hdmi_in.mode.width),\n",
    "                    dtype=np.uint8)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for _ in range(numframes):\n",
    "    inframe = hdmi_in.readframe()\n",
    "    cv2.cvtColor(inframe,cv2.COLOR_BGR2GRAY,dst=grayscale)\n",
    "    inframe.freebuffer()\n",
    "    cv2.Laplacian(grayscale, cv2.CV_8U, dst=result)\n",
    "\n",
    "    outframe = hdmi_out.newframe()\n",
    "    cv2.cvtColor(result, cv2.COLOR_GRAY2BGR,dst=outframe)\n",
    "    hdmi_out.writeframe(outframe)\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Frames per second:  \" + str(numframes / (end - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up\n",
    "\n",
    "Finally you must always stop the interfaces when you are done with them. Otherwise bad things can happen when the bitstream is reprogrammed. You can also use the HDMI interfaces in a context manager to ensure that the cleanup is always performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_out.close()\n",
    "hdmi_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gray-scale\n",
    "Using the new infrastructure we can delegate the color conversion to the hardware as well as only passing a single grayscale pixel to and from the processor.\n",
    "\n",
    "First reconfigure the pipelines in grayscale mode and tie the two together to make sure everything is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.download()\n",
    "\n",
    "hdmi_in.configure(PIXEL_GRAY)\n",
    "hdmi_out.configure(hdmi_in.mode)\n",
    "\n",
    "hdmi_in.start()\n",
    "hdmi_out.start()\n",
    "\n",
    "hdmi_in.tie(hdmi_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we can rewrite the loop without the software colour conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "numframes = 30\n",
    "\n",
    "for _ in range(numframes):\n",
    "    inframe = hdmi_in.readframe()\n",
    "    outframe = hdmi_out.newframe()\n",
    "    cv2.Laplacian(inframe, cv2.CV_8U, dst=outframe)\n",
    "    inframe.freebuffer()\n",
    "    hdmi_out.writeframe(outframe)\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Frames per second:  \" + str(numframes / (end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_out.close()\n",
    "hdmi_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other modes\n",
    "\n",
    "There are two other 24 bit modes that are useful for interacting with PIL. The first is regular RGB mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.download()\n",
    "\n",
    "hdmi_in.configure(PIXEL_BGR)\n",
    "hdmi_out.configure(hdmi_in.mode, PIXEL_BGR)\n",
    "\n",
    "hdmi_in.start()\n",
    "hdmi_out.start()\n",
    "\n",
    "hdmi_in.tie(hdmi_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful for easily creating and displaying frames with Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "\n",
    "frame = hdmi_in.readframe()\n",
    "image = PIL.Image.fromarray(frame)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative mode is YCbCr which is useful for some image processing algorithms or exporting JPEG files. Because we are not changing the number of bits per pixel we can update the colorspace of the input dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_in.colorspace = COLOR_IN_YCBCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's probably worth updating the output colorspace as well to avoid the psychedelic  effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_out.colorspace = COLOR_OUT_YCBCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use PIL to read in the frame an perform the conversion back for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "\n",
    "frame = hdmi_in.readframe()\n",
    "image = PIL.Image.fromarray(frame, \"YCbCr\")\n",
    "frame.freebuffer()\n",
    "image.convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_out.close()\n",
    "hdmi_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This notebook has only provided an overview of base overlay pipeline. One of the reasons for the changes was to make it easier to add hardware accelerated functions by supporting a wider range of pixel formats without software conversion and separating out the HDMI front end from the video DMA. Explore the code in pynq/lib/video.py for more details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
